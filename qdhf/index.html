<!DOCTYPE html>
<html>

<head lang="en">
  <meta charset="UTF-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">

  <title>QDHF</title>

  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:image" content="https://liding.info/qdhf/img/teaser.jpg">
  <meta property="og:image:type" content="image/png">
  <meta property="og:image:width" content="1296">
  <meta property="og:image:height" content="840">
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://liding.info/qdhf/" />
  <meta property="og:title" content="Quality Diversity through Human Feedback" />
  <meta property="og:description"
    content="We introduce Quality Diversity through Human Feedback (QDHF), a novel approach integrating human feedback into the QD framework. QDHF infers diversity metrics from human judgments of similarity among solutions, thereby enhancing the applicability and effectiveness of QD algorithms. Our empirical studies show that QDHF significantly outperforms state-of-the-art methods in automatic diversity discovery and matches the efficacy of using manually crafted metrics for QD on standard benchmarks in robotics and reinforcement learning. Notably, in a latent space illumination task, QDHF substantially enhances the diversity in images generated by a diffusion model and was more favorably received in user studies. We conclude by analyzing QDHF’s scalability and the quality of its derived diversity metrics, emphasizing its potential to improve exploration and diversity in complex, open-ended optimization tasks. " />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Quality Diversity through Human Feedback" />
  <meta name="twitter:description"
    content="We introduce Quality Diversity through Human Feedback (QDHF), a novel approach integrating human feedback into the QD framework. QDHF infers diversity metrics from human judgments of similarity among solutions, thereby enhancing the applicability and effectiveness of QD algorithms. Our empirical studies show that QDHF significantly outperforms state-of-the-art methods in automatic diversity discovery and matches the efficacy of using manually crafted metrics for QD on standard benchmarks in robotics and reinforcement learning. Notably, in a latent space illumination task, QDHF substantially enhances the diversity in images generated by a diffusion model and was more favorably received in user studies. We conclude by analyzing QDHF’s scalability and the quality of its derived diversity metrics, emphasizing its potential to improve exploration and diversity in complex, open-ended optimization tasks. " />
  <meta name="twitter:image" content="https://liding.info/qdhf/img/teaser.jpg" />


  <link rel="icon" href="../images/logos/favicon.png">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="css/app.css">

  <link rel="stylesheet" href="css/bootstrap.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

  <script src="js/app.js"></script>
  <script src="js/video_comparison.js"></script>
</head>

<body>
  <div class="container" id="main">
    <div class="row">
      <h2 class="col-md-12 text-center">
        Quality Diversity through Human Feedback: <br>
        Towards Open-Ended Diversity-Driven Optimization
      </h2>
      <h3 class="col-md-12 text-center">
        ICML 2024 <br>
      </h3>
      <h4 class="col-md-12 text-center">
        NeurIPS 2023: ALOE Workshop (Spotlight)
      </h4>
      <br>
    </div>
    <div class="row">
      <div class="col-md-12 text-center">
        <ul class="list-inline">
          <li>
            <a href="https://liding.info/">
              Li Ding
            </a><br>
            UMass Amherst<br><br><br>
          </li>
          <li>
            <a href="https://www.jennyzhangzt.com/">
              Jenny Zhang
            </a><br>
            Univ. of British Columbia<br>
            Vector Institute<br><br>
          </li>
          <li>
            <a href="http://jeffclune.com/">
              Jeff Clune
            </a><br>
            Univ. of British Columbia<br>
            Vector Institute<br>
            Canada CIFAR AI Chair<br>
          </li>
          <li>
            <a href="https://lspector.github.io/">
              Lee Spector
            </a><br>
            Amherst College<br>
            UMass Amherst<br><br>
          </li>
          <li>
            <a href="http://joellehman.com/">
              Joel Lehman
            </a><br>
            Stochastic Labs<br>
            (Work done at Stability AI)<br><br>
          </li>
          </br>
        </ul>
      </div>
    </div>


    <div class="row">
      <div class="col-md-4 col-md-offset-4 text-center">
        <ul class="nav nav-pills nav-justified">
          <li>
            <a href="https://arxiv.org/abs/2310.12103">
              <image src="img/icons/paper.png" height="60px"></image>
              <h4><strong>Paper</strong></h4>
            </a>
          </li>
          <li>
            <a href="https://huggingface.co/spaces/jennyzzt/quality-diversity-through-human-feedback">
              <image src="img/icons/gradio.png" height="60px"></image>
              <h4><strong>Demo</strong></h4>
            </a>
          </li>
          <li>
            <a href="https://neurips.cc/virtual/2023/83789">
              <image src="img/icons/talk.png" height="60px">
                <h4><strong>Talk</strong></h4>
            </a>
          </li>
          <li>
            <a href="https://github.com/ld-ing/qdhf">
              <image src="img/icons/github.png" height="60px">
                <h4><strong>Code</strong></h4>
            </a>
          </li>
          <li>
            <a href="https://docs.pyribs.org/en/stable/tutorials/qdhf.html">
              <image src="img/icons/pyribs.png" height="60px">
                <h4><strong>Tutorial</strong></h4>
            </a>
        </ul>
      </div>
    </div>
    <br>


    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <image src="img/teaser.jpg" width="100%"></image>
        <!-- <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/teaser.mp4" type="video/mp4" />
                </video> -->
        <small>
        </small>
        <p align="center">
          <small>
            QDHF (right) improves the diversity in text-to-image generation results compared to best-of-N
            (left) using Stable Diffusion.
          </small>
        </p>
        </h2>
      </div>
    </div>
    <hr>


    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h3>
          Abstract
        </h3>
        <p class="text-justify">
          Reinforcement Learning from Human Feedback (RLHF) has shown potential in qualitative tasks where easily
          defined performance measures are lacking. However, there are drawbacks when RLHF is commonly used to optimize
          for average human preferences, especially in generative tasks that demand diverse model responses. Meanwhile,
          Quality Diversity (QD) algorithms excel at identifying diverse and high-quality solutions but often rely on
          manually crafted diversity metrics. This paper introduces Quality Diversity through Human Feedback (QDHF), a
          novel approach that progressively infers diversity metrics from human judgments of similarity among solutions,
          thereby enhancing the applicability and effectiveness of QD algorithms in complex and open-ended domains.
          Empirical studies show that QDHF significantly outperforms state-of-the-art methods in automatic diversity
          discovery and matches the efficacy of QD with manually crafted diversity metrics on standard benchmarks in
          robotics and reinforcement learning. Notably, in open-ended generative tasks, QDHF substantially enhances the
          diversity of text-to-image generation from a diffusion model and is more favorably received in user studies.
          We conclude by analyzing QDHF's scalability, robustness, and quality of derived diversity metrics, emphasizing
          its strength in open-ended optimization tasks. Code and tutorials are available at <a
            href="https://liding.info/qdhf">https://liding.info/qdhf</a>.
        </p>
      </div>
    </div>
    <hr>

    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h3>
          Method
        </h3><br>
        <div class="text-center">
          <image src="img/qdhf_method.png" width="75%"></image>
        </div>
        <br>
        <p class="text-justify">
          The main idea is to derive distinct representations of what humans find interestingly different, and
          incorporate this procedure in QD algorithms.<br>
        <ul>
          <li>Diversity Characterization: A latent projection is used to model representations of diversity as
            its measures.</li>
          <li>Alignment: We use contrastive learning to align the diversity representations to human
            intuition.</li>
          <li>Progressive Optimization: As novel solutions are found, more human feedback is collected to
            refine the diversity representation.</li>

        </ul>
        </p>
      </div>
    </div>
    <hr>

    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h3>
          Robotic/RL (Policy Search)
        </h3><br>

        <div id="slider1" class="slider">
          <img src="img/maze_heat.png" class="slide" style="display: block;">
          <div class="caption" style="display: block;">Maze Navigation</div>

          <img src="img/arm_heat.png" class="slide">
          <div class="caption">Robotic Arm</div>

          <a class="prev" onclick="moveSlide(-1, 'slider1')">❮</a>
          <a class="next" onclick="moveSlide(1, 'slider1')">❯</a>
        </div><br><br>

        <p class="text-justify">
          Each point on the heatmap is a solution with its objective
          value visualized in color. QDHF fills up the archives with more solutions than AURORA, and closely
          matches the search performance of QD using the ground truth diversity metrics. <br><br>
          Notably, in the maze navigation task, while both
          AURORA and QDHF learned a rotated version of the maze as diversity (first column), QDHF is
          able to more accurately learn the scale of the maze especially in the under-explored area.
        </p>
      </div>
    </div>
    <hr>

    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h3>
          Open-Ended Generation (Latent Space Illumination)
        </h3><br>

        <div id="slider2" class="slider">
          <img src="img/1.jpg" class="slide" style="display: block;">
          <div class="caption" style="display: block;">a photo of an astronaut riding a horse on mars</div>

          <img src="img/2.jpg" class="slide">
          <div class="caption"> an image of a bear in a national park</div>

          <img src="img/3.jpg" class="slide">
          <div class="caption"> an image of a cat on the sofa</div>

          <img src="img/4.jpg" class="slide">
          <div class="caption">an image of a person playing guitar</div>

          <img src="img/5.jpg" class="slide">
          <div class="caption">an image of a dog in the park</div>

          <img src="img/6.jpg" class="slide">
          <div class="caption">an image of urban downtown</div>

          <a class="prev" onclick="moveSlide(-1, 'slider2')">❮</a>
          <a class="next" onclick="moveSlide(1, 'slider2')">❯</a>
        </div><br><br>
        <p class="text-justify">
          QDHF substantially enhances the variations in images
          generated by a diffusion model. The results show
          visible trends of diversity, and was more favorably received
          in user studies.
        </p>
      </div>
    </div>
    <hr>

    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h3>
          Citation
        </h3>
        <div class="form-group col-md-10 col-md-offset-1">
          <textarea id="bibtex" class="form-control" readonly>
@inproceedings{
    ding2024quality,
    title={Quality Diversity through Human Feedback: Towards Open-Ended Diversity-Driven Optimization},
    author={Li Ding and Jenny Zhang and Jeff Clune and Lee Spector and Joel Lehman},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=9zlZuAAb08}
}
                    </textarea>
        </div>
      </div>
    </div>

    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h3>
          Acknowledgements
        </h3>
        <p class="text-justify">
          <small>
            Li Ding and Lee Spector were supported by the National Science Foundation under Grant No. 2117377.
            Jeff Clune and Jenny Zhang were supported by the Vector Institute, a grant from Schmidt Futures, an NSERC
            Discovery Grant, and a generous donation from Rafael Cosman. Any opinions, findings, and conclusions or
            recommendations expressed in this publication are those of the authors and do not necessarily reflect the
            views of the funding agencies.
            The authors would like to thank Andrew Dai and Herbie Bradley for insightful suggestions, Bryon Tjanaka for
            help preparing the tutorial, members of the PUSH lab at Amherst College, University of Massachusetts
            Amherst, and Hampshire College for helpful discussions, and anonymous reviewers for their thoughtful
            feedback.
            This work utilized resources from Unity, a collaborative, multi-institutional high-performance computing
            cluster at the Massachusetts Green High Performance Computing Center (MGHPCC).

            <br><br>
            The website template was borrowed from <a href="https://jonbarron.info/"><small>Jon
                Barron</small></a>.
          </small>
          <br><br>
        </p>
      </div>
    </div>
  </div>


  <script>
    function moveSlide(n, sliderId) {
      var slider = document.getElementById(sliderId);
      var slides = slider.getElementsByClassName("slide");
      var captions = slider.getElementsByClassName("caption");
      var slideIndex = parseInt(slider.getAttribute("data-slide-index")) || 0;

      slideIndex += n;

      if (slideIndex >= slides.length) { slideIndex = slides.length - 1; }
      if (slideIndex < 0) { slideIndex = 0; }

      for (var i = 0; i < slides.length; i++) {
        slides[i].style.display = "none";
        captions[i].style.display = "none";
      }

      slides[slideIndex].style.display = "block";
      captions[slideIndex].style.display = "block";
      slider.setAttribute("data-slide-index", slideIndex);
    }
  </script>

</body>

</html>